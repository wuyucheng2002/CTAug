from torch_geometric import seed_everything
import warnings
import argparse
from CTAug import *
warnings.filterwarnings("ignore")


def get_parser():
    parser = argparse.ArgumentParser(description='CTAug Arguments.')

    # Key setting
    parser.add_argument("--method", type=str, default='GraphCL_AUG_OGSN',
                        help="Use different contrastive learning methods. Can be chosen from "
                             "graph-level CTAug: {'GraphCL_AUG_OGSN', 'JOAO_AUG_OGSN', 'MVGRL_AUG_OGSN'}, "
                             "graph-level baselines: {'GraphCL', 'MVGRL', 'JOAO', 'JOAOv2', 'InfoGraph'}, "
                             "node-level CTAug: {'GCA_AUG_OGSN', 'GRACE_AUG_OGSN'}, "
                             "node-level baselines: {'GCA', 'GRACE'}.")
    parser.add_argument("--dataset", type=str, default='IMDB-BINARY',
                        help="Dataset name, can be chosen from "
                             "graph classification: {'IMDB-BINARY', 'IMDB-MULTI', 'REDDIT-BINARY', "
                             "                       'COLLAB', 'reddit_threads', 'ENZYMES', 'PROTEINS'}, "
                             "node classification: {'Coauthor-Phy', 'Amazon-Computers'}.")
    parser.add_argument("--feature", type=str, default='sub',
                        help="Use input features generated by different methods, can be chosen from "
                             "{'one': use vector [1] as the feature of each node, "
                             " 'sub': use substructure counts as node feature (which is needed in O-GSN}, "
                             " 'deg': use one-hot degree as node feature, "
                             " 'sub_deg': concatenate substructure counts and one-hot degree as node feature}.")
    parser.add_argument("--dataset_file", type=str, default=None,
                        help="Dataset file name (containing substructure counting),"
                             "the dataset should be placed under 'data/' folder.")

    # Basic setting
    parser.add_argument("--seed", type=int, default=42,
                        help="Random seed.")
    parser.add_argument("--times", type=int, default=5,
                        help="The number of repetitions of the experiment.")
    parser.add_argument("--save_path", type=str, default=None,
                        help="The name of the folder to save log. "
                             "The default path is a subfolder named as method name under the folder 'log'.")
    parser.add_argument("--device", type=str, default=None,
                        help="Running environment, 'cpu' or 'cuda'.")

    # Dataset Preprocessing and augmentation
    parser.add_argument("--pn", type=float, default=0.2,
                        help="The probability of dropping node, removing edge, or sampling subgraph.")
    parser.add_argument("--factor", type=float, default=0.2,
                        help="The decay factor of dropping probability in CTAug-Pro, "
                             "or the factor considering cohesive property in CTAug-DT.")
    parser.add_argument("--cal_weight", type=str, default='node',
                        help="Choose the edge weight calculation strategy from {'node', 'edge'}."
                             "Only used in CTAug-MVGRL method.")
    parser.add_argument("--core", type=str, default='both',
                        help="Subgraph property, can be chosen from {'kcore', 'ktruss', 'both'}."
                             "It's only used in CTAug-GRACE and CTAug-GCA methods.")

    # Model training
    parser.add_argument("--epoch", type=int, default=None,
                        help="Training epoch.")
    parser.add_argument("--batch_size", type=int, default=64,
                        help="Batch size of dataset partition.")
    parser.add_argument("--shuffle", type=bool, default=True,
                        help="Shuffle the graphs in the dataset or not.")
    parser.add_argument("--hid_units", type=int, default=128,
                        help="Dimension of hidden layers and embedding.")
    parser.add_argument("--num_layer", type=int, default=2,
                        help="Number of GConv layers.")
    parser.add_argument("--sample", type=int, default=None,
                        help="Number of sampled graphs to train model.")

    # Model Saving and evaluation
    parser.add_argument("--interval", type=int, default=None,
                        help="Interval epoch to test.")
    parser.add_argument("--save_model", type=bool, default=False,
                        help="Whether to save the model.")
    parser.add_argument("--save_embed", type=bool, default=True,
                        help="Whether to save the model.")
    parser.add_argument("--eval_model", type=bool, default=True,
                        help="Evaluate immediately or save the model.")
    parser.add_argument("--norm", type=bool, default=False,
                        help="Whether normalize embedding before logistic regression test.")

    return parser


# Automatic setting of some hyper-parameters
def arg_parse(parser0):
    args = parser0.parse_args()

    if args.device is None:
        args.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    else:
        args.device = torch.device(args.device)

    if args.save_path is None:
        args.save_path = 'log/' + args.method + '_' + args.feature + '_' + args.dataset

    if 'sub' in args.feature and args.dataset_file is None:
        if args.dataset in ['PROTEINS', 'ENZYMES']:
            # These datsets use cycle graphs (3/4/5-cycle) as substructures
            args.dataset_file = args.dataset + '_global_cycle_graph_5.pt'
        elif args.dataset in ['IMDB-BINARY', 'IMDB-MULTI', 'REDDIT-BINARY', 'reddit_threads']:
            # These datsets use complete graphs (3/4/5-clique) as substructures
            args.dataset_file = args.dataset + '_global_complete_graph_5.pt'
        elif args.dataset in ['COLLAB']:
            # These datsets use complete graphs (3-clique) as substructures
            args.dataset_file = args.dataset + '_global_complete_graph_3.pt'
        else:
            raise NotImplementedError

    if 'OGSN' in args.method:
        assert 'sub' in args.feature

    # if args.norm is None:
    #     if 'MVGRL' in args.method:
    #         args.norm = False
    #     else:
    #         args.norm = (args.feature != 'one')

    if args.epoch is None:
        if 'MVGRL' in args.method:
            args.epoch = 50
        else:
            if args.dataset == 'REDDIT-BINARY':
                args.epoch = 200
            else:
                args.epoch = 100

    if args.interval is None:
        if 'MVGRL' in args.method:
            args.interval = 10
        else:
            args.interval = 20
            # if args.dataset == 'REDDIT-BINARY':
            #     args.interval = 10
            # else:
            #     args.interval = 20

    if not os.path.exists(args.save_path):
        os.makedirs(args.save_path)

    if 'sub' in args.feature:
        args.save_path += '/' + args.dataset_file.split('.')[0]
    else:
        args.save_path += '/' + args.dataset

    if args.sample is not None and 'GraphCL' in args.method:
        args.save_path += '_' + str(args.sample)

    assert args.core in ['kcore', 'ktruss', 'both']
    assert 0 < args.pn < 1
    assert args.cal_weight in ['node', 'edge']
    return args


if __name__ == '__main__':
    parser = get_parser()
    args = parser.parse_args()
    # 'GCA', 'GCA_AUG_OGSN', 'GRACE', 'GRACE_AUG_OGSN'
    if 'GCA' in args.method or 'GRACE' in args.method:
        CTAug_node(parser)
    else:
        args = arg_parse(parser)
        seed_everything(args.seed)
        method = Method(args)
        method.train()


